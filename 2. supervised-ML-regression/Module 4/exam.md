1.
Question 1
Which of the following statements about model complexity is TRUE? 



Higher model complexity leads to a lower chance of overfitting.


Higher model complexity leads to a higher chance of overfitting. 


Reducing the number of features while adding feature interactions leads to a lower chance of overfitting.


Reducing the number of features while adding feature interactions leads to a higher chance of overfitting. 

2.
Question 2
Which of the following statements about model errors is TRUE? 

Underfitting is characterized by lower errors in both training and test samples. 


Underfitting is characterized by higher errors in both training and test samples. 


Underfitting is characterized by higher errors in training samples and lower errors in test samples. 


Underfitting is characterized by lower errors in training samples and higher errors in test samples. 

3.
Question 3
Which of the following statements about regularization is TRUE? 



Regularization always reduces the number of selected features. 


Regularization increases the likelihood of overfitting relative to training data. 


Regularization decreases the likelihood of overfitting relative to training data.


Regularization performs feature selection without a negative impact in the likelihood of overfitting relative to the training data.

4.
Question 4
Which of the following statements about scaling features prior to regularization is TRUE?



Feature scaling is not recommented prior to regularization.


Features should rarely or never be scaled prior to implementing regularization.


The larger a feature’s scale, the more likely its estimated impact will be influenced by regularization.


The smaller a feature’s scale, the more likely its estimated impact will be influenced by regularization.

5.
Question 5
Which one of the 3 Regularization techniques: Ridge, Lasso, and Elastic Net, performs the fastest under the hood? 



Ridge


Lasso


Elastic Net


None of the above

6.
Question 6
Which of the following statements about Elastic Net regression is TRUE?



Elastic Net combines L1 and L2 regularization. 


Elastic Net does not use L1 or L2 regularization. 


Elastic Net uses L2 regularization, as with Ridge regression. 


Elastic Net uses L1 regularization, as with Ridge regression. 

7.
Question 7
BOTH Ridge regression and Lasso regression 



Do not adjust the cost function used to estimate a model. 


Add a term to the loss function proportional to a regularization parameter.


Add a term to the loss function proportional to the square of parameter coefficients.


Add a term to the loss function proportional to the absolute value of parameter coefficients. 

8.
Question 8
Compared with Lasso regression (assuming similar implementation), Ridge regression is: 



Less likely to overfit to training data. 


More likely to overfit to training data. 


Less likely to set feature coefficients to zero. 


More likely to set feature coefficients to zero. 

9.
Question 9
Which of the following about Ridge Regularization is TRUE?



It enforces the coefficients to be lower, but not 0


It minimizes irrelevant features 


It penalizes the size  magnitude of the regression coefficients by adding a squared term 


All of the above

10. Question 10
Whixh of the below statements are correct?


Neither RidgeCV nor LassoCV use L1 regularization function.


Both RidgeCV and LassoCV use L1 regularization function.


Only RidgeCV use L1 regularization function.


Only LassoCV use L1 regularization function.